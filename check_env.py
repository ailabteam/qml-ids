import torch
import pennylane as qml

print("--- Hybrid GPU(PyTorch)/CPU(PennyLane) Environment Check ---")
print(f"PyTorch version: {torch.__version__}")
print(f"PennyLane version: {qml.__version__}")

# 1. Kiá»ƒm tra GPU cho PyTorch
if not torch.cuda.is_available():
    raise RuntimeError("ERROR: PyTorch cannot find GPU!")
print(f"âœ… PyTorch CUDA available: True ({torch.cuda.get_device_name(0)})")

# 2. Äá»‹nh nghÄ©a thiáº¿t bá»‹ lÆ°á»£ng tá»­ an toÃ n (cháº¡y trÃªn CPU)
n_qubits = 4
# default.qubit lÃ  trÃ¬nh mÃ´ phá»ng an toÃ n, khÃ´ng cáº§n build
device = qml.device("default.qubit", wires=n_qubits)
print(f"âœ… PennyLane device '{device.name}' loaded successfully (runs on CPU).")

# 3. Äá»‹nh nghÄ©a QNode vÃ  lá»›p PyTorch
@qml.qnode(device, interface='torch')
def quantum_circuit(inputs):
    qml.AngleEmbedding(inputs, wires=range(n_qubits))
    return qml.expval(qml.PauliZ(0))

# Lá»›p lÆ°á»£ng tá»­ cÃ³ 4 input (cho 4 qubit) vÃ  1 output
qlayer = qml.qnn.TorchLayer(quantum_circuit, weight_shapes={})

# 4. Kiá»ƒm tra Forward/Backward pass trÃªn GPU
print("\n--- Testing Hybrid Forward/Backward Pass ---")

# Táº¡o má»™t lá»›p cá»• Ä‘iá»ƒn vÃ  lá»›p lÆ°á»£ng tá»­
# Lá»›p linear sáº½ cháº¡y trÃªn GPU
classical_layer = torch.nn.Linear(10, n_qubits) 
model = torch.nn.Sequential(classical_layer, qlayer)

# Chuyá»ƒn mÃ´ hÃ¬nh lÃªn GPU
gpu_device = torch.device("cuda:0")
model.to(gpu_device)
print(f"âœ… Model moved to {gpu_device}")

# Dá»¯ liá»‡u Ä‘áº§u vÃ o trÃªn GPU
inputs = torch.randn(5, 10, device=gpu_device)

# Forward pass
print("Performing forward pass...")
# PyTorch tá»± Ä‘á»™ng xá»­ lÃ½:
# - inputs -> classical_layer (trÃªn GPU)
# - output cá»§a classical_layer -> CPU -> qlayer (trÃªn CPU)
# - output cá»§a qlayer -> GPU
result = model(inputs)
print(f"Input shape: {inputs.shape}, Device: {inputs.device}")
print(f"Output shape: {result.shape}, Device: {result.device}")

# Backward pass
result.sum().backward()
print("âœ… Backward pass successful.")
print("\nðŸŽ‰ SUCCESS! Your hybrid GPU/CPU environment is ready for research.")
